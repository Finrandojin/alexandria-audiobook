<!-- Setup Tab -->
<div id="setup-tab" class="tab-content">
    <div class="card">
        <div class="card-header">
            <h4><span class="step-indicator step-active">1</span>Configuration</h4>
        </div>
        <div class="card-body">
            <form id="config-form">
                <h5 class="mb-3">LLM Settings (Script Generation)</h5>
                <div class="mb-3">
                    <label class="form-label">Base URL</label>
                    <input type="text" class="form-control" id="llm-url" placeholder="http://localhost:1234/v1">
                    <div class="form-text">URL for your OpenAI-compatible server (LM Studio, Ollama, etc.)</div>
                </div>
                <div class="mb-3">
                    <label class="form-label">API Key</label>
                    <input type="text" class="form-control" id="llm-key" value="local">
                </div>
                <div class="mb-3">
                    <label class="form-label">Model Name</label>
                    <input type="text" class="form-control" id="llm-model" placeholder="local-model">
                </div>

                <h5 class="mb-3 mt-4">TTS Settings (Voice Generation)</h5>
                <div class="row mb-3">
                    <div class="col-md-3">
                        <label class="form-label">TTS Mode</label>
                        <select class="form-select" id="tts-mode" onchange="toggleTTSMode()">
                            <option value="external">External Server</option>
                            <option value="local">Local Model</option>
                        </select>
                        <div class="form-text">Local loads model in-process; External connects to a Gradio TTS server</div>
                    </div>
                    <div class="col-md-5" id="tts-url-group">
                        <label class="form-label">TTS Server URL</label>
                        <input type="text" class="form-control" id="tts-url" value="http://127.0.0.1:7860">
                        <div class="form-text">URL for the Qwen3-TTS Gradio server</div>
                    </div>
                    <div class="col-md-4" id="tts-device-group" style="display:none;">
                        <label class="form-label">Device</label>
                        <select class="form-select" id="tts-device">
                            <option value="auto">Auto (best available)</option>
                            <option value="cuda:0">CUDA GPU 0</option>
                            <option value="cuda:1">CUDA GPU 1</option>
                            <option value="cpu">CPU</option>
                        </select>
                        <div class="form-text">Device for local model inference</div>
                    </div>
                    <div class="col-md-3" id="tts-language-group">
                        <label class="form-label">Language</label>
                        <select class="form-select" id="tts-language">
                            <option value="Auto">Auto (detect)</option>
                            <option value="English" selected>English</option>
                            <option value="Chinese">Chinese</option>
                            <option value="French">French</option>
                            <option value="German">German</option>
                            <option value="Italian">Italian</option>
                            <option value="Japanese">Japanese</option>
                            <option value="Korean">Korean</option>
                            <option value="Portuguese">Portuguese</option>
                            <option value="Russian">Russian</option>
                            <option value="Spanish">Spanish</option>
                        </select>
                        <div class="form-text">Language for TTS synthesis</div>
                    </div>
                    <div class="col-md-2">
                        <label class="form-label">Parallel Workers</label>
                        <input type="number" class="form-control" id="parallel-workers" value="2" min="1">
                        <div class="form-text">Concurrent TTS requests</div>
                    </div>
                    <div class="col-md-2">
                        <label class="form-label">Batch Seed</label>
                        <input type="number" class="form-control" id="batch-seed" placeholder="-1 (random)">
                        <div class="form-text">Seed for reproducibility</div>
                    </div>
                </div>
                <div class="row mb-3" id="tts-local-options" style="display:none;">
                    <div class="col-md-2">
                        <div class="form-check form-switch mt-4">
                            <input class="form-check-input" type="checkbox" id="compile-codec">
                            <label class="form-check-label" for="compile-codec">Compile Codec</label>
                        </div>
                        <div class="form-text">torch.compile the audio codec (~3-4x batch speed, slow first run)</div>
                    </div>
                    <div class="col-md-2">
                        <div class="form-check form-switch mt-4">
                            <input class="form-check-input" type="checkbox" id="sub-batch-enabled" checked>
                            <label class="form-check-label" for="sub-batch-enabled">Sub-batching</label>
                        </div>
                        <div class="form-text">Split batches by text length to reduce padding waste</div>
                    </div>
                    <div class="col-md-2" id="sub-batch-min-group">
                        <label class="form-label">Min Sub-batch Size</label>
                        <input type="number" class="form-control" id="sub-batch-min-size" value="4" min="1">
                        <div class="form-text">Min chunks before splitting</div>
                    </div>
                    <div class="col-md-2" id="sub-batch-ratio-group">
                        <label class="form-label">Length Ratio</label>
                        <input type="number" class="form-control" id="sub-batch-ratio" value="5" min="1" step="0.5">
                        <div class="form-text">Max long/short ratio before split</div>
                    </div>
                </div>

                <h5 class="mb-3 mt-4">
                    <a class="text-decoration-none" data-bs-toggle="collapse" href="#promptSettings" role="button" aria-expanded="false">
                        <i class="fas fa-chevron-right me-2" id="prompt-chevron"></i>Prompt Settings (Advanced)
                    </a>
                </h5>
                <div class="collapse" id="promptSettings">
                    <h6 class="mb-3">Generation Settings</h6>
                    <div class="row mb-3">
                        <div class="col-md-6">
                            <label class="form-label">Chunk Size (characters)</label>
                            <input type="number" class="form-control" id="chunk-size" value="3000" min="500">
                            <div class="form-text">Size of text chunks sent to LLM (characters). Smaller = more precise, larger = more context.</div>
                        </div>
                        <div class="col-md-6">
                            <label class="form-label">Max Tokens (response)</label>
                            <input type="number" class="form-control" id="max-tokens" value="4096" min="256">
                            <div class="form-text">Maximum tokens for LLM response. Increase if output is being truncated.</div>
                        </div>
                    </div>
                    <h6 class="mb-3">LLM Sampling Parameters</h6>
                    <div class="row mb-3">
                        <div class="col">
                            <label class="form-label">Temperature</label>
                            <input type="number" class="form-control" id="temperature" value="0.6" min="0" max="2" step="0.05">
                            <div class="form-text">Randomness (0 = deterministic)</div>
                        </div>
                        <div class="col">
                            <label class="form-label">Top P</label>
                            <input type="number" class="form-control" id="top-p" value="0.8" min="0" max="1" step="0.05">
                            <div class="form-text">Nucleus sampling threshold</div>
                        </div>
                        <div class="col">
                            <label class="form-label">Top K</label>
                            <input type="number" class="form-control" id="top-k" value="20" min="0" max="200" step="1">
                            <div class="form-text">Top-K token filtering</div>
                        </div>
                        <div class="col">
                            <label class="form-label">Min P</label>
                            <input type="number" class="form-control" id="min-p" value="0" min="0" max="1" step="0.01">
                            <div class="form-text">Minimum probability cutoff</div>
                        </div>
                        <div class="col">
                            <label class="form-label">Presence Penalty</label>
                            <input type="number" class="form-control" id="presence-penalty" value="0" min="-2" max="2" step="0.1">
                            <div class="form-text">Penalize repeated topics</div>
                        </div>
                    </div>
                    <div class="mb-3">
                        <label class="form-label">Banned Tokens</label>
                        <input type="text" class="form-control" id="banned-tokens" placeholder="e.g. <think>, <reasoning>">
                        <div class="form-text">Comma-separated tokens the LLM is forbidden from generating. Use to disable thinking mode (e.g. <code>&lt;think&gt;</code>).</div>
                    </div>
                    <hr>
                    <h6 class="mb-3">Prompt Customization</h6>
                    <div class="mb-3">
                        <label class="form-label">System Prompt</label>
                        <textarea class="form-control font-monospace" id="system-prompt" rows="12" style="font-size: 0.85em;"></textarea>
                        <div class="form-text">Instructions for the LLM on how to convert text to script. Defines output format, rules, and style guidelines.</div>
                    </div>
                    <div class="mb-3">
                        <label class="form-label">User Prompt Template</label>
                        <textarea class="form-control font-monospace" id="user-prompt" rows="4" style="font-size: 0.85em;"></textarea>
                        <div class="form-text">Template for each chunk. Use <code>{context}</code> for chunk context and <code>{chunk}</code> for the text content.</div>
                    </div>
                    <button type="button" class="btn btn-outline-secondary btn-sm mb-3" onclick="resetPrompts()">
                        <i class="fas fa-undo me-1"></i>Reset to Defaults
                    </button>
                </div>

                <button type="submit" class="btn btn-primary"><i class="fas fa-save me-2"></i>Save Configuration</button>
            </form>
        </div>
    </div>
</div>
